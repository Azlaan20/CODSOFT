{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Machine Learning Task:** SMS Spam Detection ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by importing all the necessary libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check for any null values and any duplicates. To clean our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          v1                      v2\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">v2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v2                                                               \n",
       "     count unique                                                top freq\n",
       "v1                                                                       \n",
       "ham   4825   4516                             Sorry, I'll call later   30\n",
       "spam   747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('v1').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets move onto the data preprocessing. So that we can make our data suitable for our model. We will start by cleaning our text and removing any special characters from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Cleaning\n",
    "def clean_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  Go until jurong point crazy Available only in ...\n",
      "1   ham                            Ok lar Joking wif u oni\n",
      "2  spam  Free entry in  a wkly comp to win FA Cup final...\n",
      "3   ham        U dun say so early hor U c already then say\n",
      "4   ham  Nah I dont think he goes to usf he lives aroun...\n"
     ]
    }
   ],
   "source": [
    "data['v2'] = data['v2'].apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are done with that. It better to convert our text into lowercase so that there are no discrepancies or uneven cases in our text. This can cause problems in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Clearning (Continued)\n",
    "def lowercase_text(text):\n",
    "    # Convert text to lowercase\n",
    "    lowercase_text = text.lower()\n",
    "    return lowercase_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  go until jurong point crazy available only in ...\n",
      "1   ham                            ok lar joking wif u oni\n",
      "2  spam  free entry in  a wkly comp to win fa cup final...\n",
      "3   ham        u dun say so early hor u c already then say\n",
      "4   ham  nah i dont think he goes to usf he lives aroun...\n"
     ]
    }
   ],
   "source": [
    "data['v2'] = data['v2'].apply(lowercase_text)\n",
    "\n",
    "# Display the first few rows of the dataset with lowercase text\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just in case. I am going to download some necessary packages and update them if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Azlaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Azlaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Azlaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the process is to divide the text into small tokens. What this means is that each word of our dataset is a seperate element. That will be reviewed by our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Cleaning (Continued)\n",
    "def tokenize_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  [go, until, jurong, point, crazy, available, o...\n",
      "1   ham                     [ok, lar, joking, wif, u, oni]\n",
      "2  spam  [free, entry, in, a, wkly, comp, to, win, fa, ...\n",
      "3   ham  [u, dun, say, so, early, hor, u, c, already, t...\n",
      "4   ham  [nah, i, dont, think, he, goes, to, usf, he, l...\n"
     ]
    }
   ],
   "source": [
    "data['v2'] = data['v2'].apply(tokenize_text)\n",
    "\n",
    "# Display the first few rows of the dataset with tokenized text\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making our tokens. We are going to remove any stopwords. Stopwords are words that are not important for our model. They are words like 'the', 'a', 'an', 'is', 'are', etc. These words are not important for our model. So, we are going to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Cleaning (Continued)\n",
    "def remove_stopwords(tokens):\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  [go, jurong, point, crazy, available, bugis, n...\n",
      "1   ham                     [ok, lar, joking, wif, u, oni]\n",
      "2  spam  [free, entry, wkly, comp, win, fa, cup, final,...\n",
      "3   ham      [u, dun, say, early, hor, u, c, already, say]\n",
      "4   ham  [nah, dont, think, goes, usf, lives, around, t...\n"
     ]
    }
   ],
   "source": [
    "data['v2'] = data['v2'].apply(remove_stopwords)\n",
    "\n",
    "# Display the first few rows of the dataset with filtered text\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final step of our data preprocessing. We are going to stem our words. Stemming is the process of reducing a word to its root form. For example, the word 'running' will be reduced to 'run'. This is done so that our model can understand the words better. We are going to use the PorterStemmer for this task. Moreover, we have also provided an option to use lemmatization, if that might be better. Although a very small difference is observed between the two. However, stemming is faster than lemmatization. So, we are going to use stemming and also has a slight edge in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Cleaning (Continued)\n",
    "def apply_stemming(tokens):\n",
    "    # Apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "def apply_lemmatization(tokens):\n",
    "    # Apply lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either stemming or lemmatization\n",
    "data['v2'] = data['v2'].apply(apply_stemming)\n",
    "# or\n",
    "#data['v2'] = data['v2'].apply(apply_lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  [go, jurong, point, crazi, avail, bugi, n, gre...\n",
      "1   ham                       [ok, lar, joke, wif, u, oni]\n",
      "2  spam  [free, entri, wkli, comp, win, fa, cup, final,...\n",
      "3   ham      [u, dun, say, earli, hor, u, c, alreadi, say]\n",
      "4   ham  [nah, dont, think, goe, usf, live, around, tho...\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset with processed text\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to perform vectorization our data. This is done so that our model can understand our data better. We are going to use the TF-IDF vectorizer for this task. Additionally, this is also done so that all the words are given equal importance and the data can be tested as a whole. Hence, removing any bias and making it easier for our model to understand the data. Our features are reduced so that the models works faster and more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature Extraction (TF-IDF)\n",
    "corpus = [' '.join(tokens) for tokens in data['v2']]\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (5169, 7050)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the layman, TF-IDF is a measure of originality of a word by comparing the number of times a word appears in a document with the number of documents the word appears in. Hence, giving us a measure of how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, I have seperately made the label variable so it would be easier for anyone reading to understand the code. The column v1 are the labels and the column v2 are the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['v1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the process is fairly common but extremely necessary part of our machine learning process. We are going to split our data into training and testing data. This is done so that we can train our model on the training data and then test it on the testing data. This is done so that we can check the accuracy of our model. We are going to use the train_test_split function from the sklearn library. We are going to use 20% of our data for testing and 80% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 'X' as your TF-IDF matrix and 'labels' as corresponding labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## **Machine Learning Model:** Naive Bayes ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by finding the parameters that are best for our model. I have used the GridSearchCV function from the sklearn library. This function will help us find the best parameters for our model. We are going to use the Multinomial Naive Bayes model for this task. Alpha is from range 0.1 to 10.0, with seperations of 0.1 for each value of alpha. Just wide range is taken so that the best results can be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: Get a free gift now! - Predicted Label: spam\n",
      "SMS: Hi, how are you? - Predicted Label: ham\n",
      "Best Score: 0.9719486049818394\n",
      "Best Estimator: MultinomialNB(alpha=0.1)\n",
      "Best Value of Alpha: {'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Naive Bayes\n",
    "param_grid_nb = {'alpha': [0.1 * i for i in range(1, 101)]}\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=3)\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "best_nb_classifier = grid_search_nb.best_estimator_\n",
    "\n",
    "# Deploy the best Naive Bayes model\n",
    "new_sms_nb = [\"Get a free gift now!\", \"Hi, how are you?\"]\n",
    "new_sms_corpus_nb = [' '.join(tokenize_text(clean_text(sms.lower()))) for sms in new_sms_nb]\n",
    "new_sms_tfidf_nb = tfidf_vectorizer.transform(new_sms_corpus_nb)\n",
    "predicted_labels_nb = best_nb_classifier.predict(new_sms_tfidf_nb)\n",
    "\n",
    "for sms, label in zip(new_sms_nb, predicted_labels_nb):\n",
    "    print(f\"SMS: {sms} - Predicted Label: {label}\")\n",
    "    \n",
    "print(f\"Best Score: {grid_search_nb.best_score_}\")\n",
    "print(f\"Best Estimator: {grid_search_nb.best_estimator_}\")\n",
    "print(f\"Best Value of Alpha: {grid_search_nb.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the Naive Bayes model for our task. We are going to use the Multinomial Naive Bayes model. This is because our data is discrete and not continuous. We are going to use the MultinomialNB function from the sklearn library. A very important thing to note is that we are going to use the fit function on our training data. This is done so that our model can learn from our training data. We will now create a model variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Model Training (Naive Bayes)\n",
    "nb_classifier = best_nb_classifier\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model. We would use that model to predict the labels of our testing data. We are going to use the predict function on our testing data. We will now create a predictions variable. Additionally, we would also check the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9758220502901354\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Evaluation\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       889\n",
      "        spam       0.92      0.91      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.95      0.95      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[877  12]\n",
      " [ 13 132]]\n"
     ]
    }
   ],
   "source": [
    "# Display classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: Get a free gift now! - Predicted Label: ham\n",
      "SMS: Hi, how are you? - Predicted Label: ham\n",
      "Best Score: 0.9680772090024078\n",
      "Best Estimator: LogisticRegression(C=10.0, max_iter=1000)\n",
      "Best Value of Alpha: {'C': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid_logreg = {'C': [0.1 * i for i in range(1, 101)]}\n",
    "grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_logreg, cv=3)\n",
    "grid_search_logreg.fit(X_train, y_train)\n",
    "best_logreg_classifier = grid_search_logreg.best_estimator_\n",
    "\n",
    "# Deploy the best Logistic Regression model\n",
    "new_sms_logreg = [\"Get a free gift now!\", \"Hi, how are you?\"]\n",
    "new_sms_corpus_logreg = [' '.join(tokenize_text(clean_text(sms.lower()))) for sms in new_sms_logreg]\n",
    "new_sms_tfidf_logreg = tfidf_vectorizer.transform(new_sms_corpus_logreg)\n",
    "predicted_labels_logreg = best_logreg_classifier.predict(new_sms_tfidf_logreg)\n",
    "\n",
    "for sms, label in zip(new_sms_logreg, predicted_labels_logreg):\n",
    "    print(f\"SMS: {sms} - Predicted Label: {label}\")\n",
    "\n",
    "print(f\"Best Score: {grid_search_logreg.best_score_}\")\n",
    "print(f\"Best Estimator: {grid_search_logreg.best_estimator_}\")\n",
    "print(f\"Best Value of Alpha: {grid_search_logreg.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=1000)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Model Training (Logistic Regression)\n",
    "logreg_classifier = best_logreg_classifier\n",
    "logreg_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9729206963249516\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Evaluation\n",
    "y_pred_logreg = logreg_classifier.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       889\n",
      "        spam       0.96      0.84      0.90       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.97      0.92      0.94      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[884   5]\n",
      " [ 23 122]]\n"
     ]
    }
   ],
   "source": [
    "# Display classification report and confusion matrix for Logistic Regression\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n",
    "print(\"\\nLogistic Regression Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS: Get a free gift now! - Predicted Label: ham\n",
      "SMS: Hi, how are you? - Predicted Label: ham\n",
      "Best Score: 0.9743656401064694\n",
      "Best Estimator: SVC(C=10, kernel='linear')\n",
      "Best Value of Alpha: {'C': 10, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1 * i for i in range(1, 101)],\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_svm_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Deploy the best SVM model\n",
    "new_sms = [\"Get a free gift now!\", \"Hi, how are you?\"]\n",
    "new_sms_corpus = [' '.join(tokenize_text(clean_text(sms.lower()))) for sms in new_sms]\n",
    "new_sms_tfidf = tfidf_vectorizer.transform(new_sms_corpus)\n",
    "predicted_labels = best_svm_classifier.predict(new_sms_tfidf)\n",
    "\n",
    "for sms, label in zip(new_sms, predicted_labels):\n",
    "    print(f\"SMS: {sms} - Predicted Label: {label}\")\n",
    "\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n",
    "print(f\"Best Estimator: {grid_search.best_estimator_}\")\n",
    "print(f\"Best Value of Alpha: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-32 {color: black;}#sk-container-id-32 pre{padding: 0;}#sk-container-id-32 div.sk-toggleable {background-color: white;}#sk-container-id-32 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-32 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-32 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-32 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-32 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-32 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-32 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-32 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-32 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-32 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-32 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-32 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-32 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-32 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-32 div.sk-item {position: relative;z-index: 1;}#sk-container-id-32 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-32 div.sk-item::before, #sk-container-id-32 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-32 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-32 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-32 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-32 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-32 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-32 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-32 div.sk-label-container {text-align: center;}#sk-container-id-32 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-32 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-32\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, kernel='linear')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Model Training (Support Vector Machines - SVM)\n",
    "svm_classifier = best_svm_classifier\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9758220502901354\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Evaluation\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.99      0.99       889\n",
      "        spam       0.95      0.87      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.97      0.93      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n",
      "\n",
      "SVM Confusion Matrix:\n",
      " [[883   6]\n",
      " [ 19 126]]\n"
     ]
    }
   ],
   "source": [
    "# Display classification report and confusion matrix for SVM\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"\\nSVM Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
